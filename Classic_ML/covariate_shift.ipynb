{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ковариантный сдвиг\n"
      ],
      "metadata": {
        "id": "pPMtejqTL5Eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Ковариантный сдвиг** (covariate shift) &mdash; явление, когда признаки тренировочной и тестовой выборок **распределены по-разному**. Ковариантный сдвиг может стать серьезной проблемой для практического применения моделей, так как модель обучается на одном распределении данных, а применяется к другому."
      ],
      "metadata": {
        "id": "AdVj7DTC5svk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKfgUf4E4fXC"
      },
      "source": [
        "<center><img src =\"https://ml.gan4x4.ru/msu/additions/L04/covariate_shift.png\" width=\"800\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим пример на изображении сверху:\n",
        "\n",
        "На тренировочной выборке мы проводим границу решения классификатора, который хорошо разделяет данные на два класса. Однако на тестовых данных распределение признаков для классов отличается, и оптимальное решение другое. Если мы будем использовать классификатор обученный на тренировочной части, то будем получать большую ошибку."
      ],
      "metadata": {
        "id": "EKhcRb2S6hEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Различают разные типы ковариантного сдвига:\n",
        "\n",
        "- **Сдвиг концепции (concept shift)**: Изменение отношения между признаками и целевой переменной. Примером может быть ситуация, когда экономические условия изменились, и показатели, которые раньше были индикаторами роста, теперь указывают на спад.\n",
        "  \n",
        "- **Сдвиг распределения меток (label shift)**: Случай, когда распределение целевой переменной (например, классов) изменяется между тренировочной и тестовой выборками, но распределение признаков остаётся неизменным. Это тоже может привести к ковариантному сдвигу.\n"
      ],
      "metadata": {
        "id": "djF8f75D_m6J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJkdJ9raMFnp"
      },
      "source": [
        "<center><img src =\"https://ml.gan4x4.ru/msu/additions/L04/covariate_shift_example.png\" width=\"450\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Причины возникновения"
      ],
      "metadata": {
        "id": "7sZMP0_8-1xI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Систематические ошибки в сборе данных**: В процессе сбора данных могут возникать предвзятости, приводящие к тому, что тренировочная выборка не репрезентативна для всей популяции данных. Например, если данные для обучения собирались в одном регионе, а данные для тестирования — в другом, различия в культурных, социальных и экономических условиях могут привести к ковариантному сдвигу.\n",
        "  \n",
        "- **Изменение условий среды**: Когда условия, при которых собираются данные, изменяются с течением времени или из-за внешних факторов, это также может вызвать ковариантный сдвиг. Например, если модель обучена на данных, собранных при дневном свете, но применяется на данных, собранных ночью, её точность может значительно снизиться.\n",
        "  \n",
        "- **Ошибки предобработки данных**: Важным источником ковариантного сдвига могут стать ошибки на этапе предобработки данных, когда, например, единицы измерения признаков в тренировочной и тестовой выборках различаются, или когда данные неправильно нормализованы.\n"
      ],
      "metadata": {
        "id": "r6k2II3N_awU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPkOs36XMFnp"
      },
      "source": [
        "\n",
        "**Пример:** стандартные наборы данных для задачи **Face Recognition** не сбалансированы по полу, возрасту и этнической принадлежности, поэтому обученные на них модели могут плохо работать с редкими классами. Это привело к обвинениям таких корпораций, как Microsoft, IBM и Amazon, в [расизме](https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGXFc1tVMFnp"
      },
      "source": [
        "<center><img src =\"https://ml.gan4x4.ru/msu/additions/L04/face_recognition_racism.webp\" width=\"800\"></center>\n",
        "<center><em>Source: <a href=\"https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/\">Racial Discrimination in Face Recognition Technology</a></em></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Примеры ковариантного сдвига:\n",
        "\n",
        "1. **Изменение пользовательского поведения**:\n",
        "   - Допустим, у нас есть рекомендательная система, которая обучалась на данных о предпочтениях пользователей в прошлом году. Со временем предпочтения пользователей могут измениться, например, из-за новых тенденций или изменения интересов. Это изменение в распределении входных данных (поведение пользователей) приведет к ковариантному сдвигу. Модель, обученная на старых данных, может показывать более низкую точность на новых данных.\n",
        "\n",
        "2. **Изменение условий съёмки**:\n",
        "   - Представим, что у нас есть модель компьютерного зрения, обученная на изображениях, сделанных при естественном дневном освещении. Если модель применяется к изображениям, сделанным при искусственном освещении или в условиях низкой освещенности, распределение входных данных изменится, что вызовет ковариантный сдвиг. Модель может начать давать менее точные предсказания, так как она не была обучена на таких измененных данных.\n",
        "\n",
        "3. **Временные ряды**:\n",
        "   - В задачах предсказания временных рядов, например, прогнозирования спроса на товар, ковариантный сдвиг может возникнуть, если внешние условия, такие как сезонность или экономическая ситуация, изменятся. Модель, обученная на данных до изменения, может оказаться менее точной, так как её предсказания базируются на прошлом распределении данных."
      ],
      "metadata": {
        "id": "1Aeeb7HSSqQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Методы обнаружения"
      ],
      "metadata": {
        "id": "qVvH0JOh_CcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **Сравнение статистических распределений признаков**\n",
        "\n",
        "Один из самых простых и очевидных методов обнаружения ковариантного сдвига — это сравнение распределений признаков в тренировочной и тестовой выборках. Если распределение признаков существенно отличается между этими выборками, это может указывать на ковариантный сдвиг. Для сравнения распределений можно использовать:\n",
        "\n",
        "- **Гистограммы и графики плотности распределения**: визуальное сравнение распределений признаков.\n",
        "- **Статистические тесты**: такие как тест [Колмогорова-Смирнова](https://ru.wikipedia.org/wiki/%D0%9A%D1%80%D0%B8%D1%82%D0%B5%D1%80%D0%B8%D0%B9_%D1%81%D0%BE%D0%B3%D0%BB%D0%B0%D1%81%D0%B8%D1%8F_%D0%9A%D0%BE%D0%BB%D0%BC%D0%BE%D0%B3%D0%BE%D1%80%D0%BE%D0%B2%D0%B0), тест [Манна-Уитни](https://ru.wikipedia.org/wiki/U-%D0%BA%D1%80%D0%B8%D1%82%D0%B5%D1%80%D0%B8%D0%B9_%D0%9C%D0%B0%D0%BD%D0%BD%D0%B0_%E2%80%94_%D0%A3%D0%B8%D1%82%D0%BD%D0%B8) и другие, которые помогают количественно оценить различия между распределениями признаков.\n"
      ],
      "metadata": {
        "id": "s6vPbw34BSdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. **Измерение \"расстояния\" между распределениями**\n",
        "\n",
        "Методы измерения \"расстояния\" между распределениями позволяют количественно оценить различия между тренировочными и тестовыми данными. К таким методам относятся:\n",
        "\n",
        "- **[Kullback-Leibler Divergence (KL-дивергенция)](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%B8%D0%B5_%D0%9A%D1%83%D0%BB%D1%8C%D0%B1%D0%B0%D0%BA%D0%B0_%E2%80%94_%D0%9B%D0%B5%D0%B9%D0%B1%D0%BB%D0%B5%D1%80%D0%B0)**: измеряет различие между двумя вероятностными распределениями, показывая, насколько одно распределение отличается от другого.\n",
        "- **[Wasserstein Distance (Earth Mover’s Distance)](https://en.wikipedia.org/wiki/Wasserstein_metric)**: измеряет минимальную \"стоимость\" преобразования одного распределения в другое, что может быть полезно для количественной оценки сдвига.\n"
      ],
      "metadata": {
        "id": "N2-SgRCED8PJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. **Использование модели для предсказания принадлежности к выборке**\n",
        "\n",
        "Другой способ обнаружения ковариантного сдвига — это построение модели (классификатора), которая предсказывает, из какой выборки (тренировочной или тестовой) происходит данный объект. Если модель может точно различать объекты из тренировочной и тестовой выборок, это может указывать на значительные различия в распределении признаков, то есть на ковариантный сдвиг. Важные моменты:\n",
        "\n",
        "- **Высокая точность модели**: если модель хорошо разделяет объекты по выборкам, это свидетельствует о сильном ковариантном сдвиге.\n",
        "- **Интерпретация важности признаков**: можно проанализировать, какие признаки вносят наибольший вклад в различие между выборками, чтобы лучше понять природу сдвига.\n"
      ],
      "metadata": {
        "id": "QS3F-hd_D-jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4. **Использование методов аномалий и кластеризации**\n",
        "\n",
        "Методы обнаружения аномалий и кластеризации могут использоваться для выявления ковариантного сдвига, когда данные в тестовой выборке значительно отличаются от тренировочной:\n",
        "\n",
        "- **Методы кластеризации**: такие как k-Means, могут помочь разделить данные на группы и выявить, если некоторые кластеры данных представлены только в одной из выборок.\n",
        "- **Методы обнаружения аномалий**: например, алгоритмы One-Class SVM или Isolation Forest могут помочь определить данные, которые существенно отличаются от типичных примеров из тренировочной выборки.\n",
        "\n"
      ],
      "metadata": {
        "id": "eN4G76kMD_zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Методы борьбы"
      ],
      "metadata": {
        "id": "-i5QufPn_R2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        " 1. **Importance Reweighting**\n",
        "\n",
        "[Importance Reweighting](https://arxiv.org/abs/1411.7718) — это метод, который заключается в пересчете весов объектов в тренировочной выборке таким образом, чтобы тренировочная выборка лучше соответствовала распределению тестовых данных. Основная идея метода заключается в следующем:\n",
        "\n",
        "- **Перераспределение весов**: объекты из тренировочной выборки, которые более похожи на объекты из тестовой выборки, получают больший вес при обучении модели.\n",
        "- **Использование плотностей распределений**: вес каждого объекта определяется как отношение плотностей признаков в тестовой и тренировочной выборках.\n",
        "\n",
        "Этот метод помогает модели лучше адаптироваться к тестовым данным, уменьшая влияние сдвига распределений.\n",
        "\n",
        "Предположим, что у нас есть два признака: возраст и доход. В тренировочной выборке у нас в основном молодые люди с высоким доходом, а в тестовой — люди старше 40 лет с разным уровнем дохода.\n",
        "\n",
        "Сначала вы оцениваете плотность распределения возрастов и доходов в обеих выборках. Затем, для каждого объекта в тренировочной выборке, вы вычисляете вес, зависящий от того, насколько возраст и доход этого объекта похожи на тестовые данные. Если в тестовой выборке много людей старше 40 лет, объекты с таким возрастом из тренировочной выборки получат больший вес.\n",
        "\n",
        "Когда модель будет обучаться, она будет обращать больше внимания на такие объекты, что позволит ей лучше работать на тестовых данных.\n",
        "\n"
      ],
      "metadata": {
        "id": "o31XTw16EPk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " 2. **Аугментация данных**\n",
        "\n",
        "\n",
        "\n",
        "Аугментация данных — это создание дополнительных тренировочных данных с помощью различных трансформаций. Этот метод позволяет увеличить разнообразие данных и сделать модель более устойчивой к изменяющимся условиям:\n",
        "\n",
        "Например, в задачах компьютерного зрения можно использовать такие методы, как вращение, масштабирование, изменение яркости и контраста, для создания новых примеров.\n",
        "\n",
        "Аугментация данных помогает модели \"увидеть\" более широкий спектр возможных вариаций признаков, что делает её более устойчивой к ковариантному сдвигу.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XI8MqL9CNUrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src =\"https://ml.gan4x4.ru/msu/additions/L04/augmentations_examples.png\" width=\"700\"></center>"
      ],
      "metadata": {
        "id": "-BXSdpoGR9Sn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " 3. **Удаление или коррекция нестационарных признаков**\n",
        "\n",
        "Некоторые признаки могут быть нестационарными и изменяться со временем, что может приводить к ковариантному сдвигу. В таких случаях важно:\n",
        "\n",
        "- **Анализ и удаление**: выявление и удаление признаков, которые наиболее подвержены изменениям, может улучшить устойчивость модели.\n",
        "- **Коррекция признаков**: если удаление признаков невозможно, можно применять методы коррекции, которые учитывают возможные изменения во времени.\n"
      ],
      "metadata": {
        "id": "9ozxt8LgNb0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " 4. **Многообразные источники данных**\n",
        "\n",
        "Использование данных из различных источников или доменов при обучении модели может помочь снизить риск ковариантного сдвига. Это достигается за счет:\n",
        "\n",
        "- **Сбор данных из разных источников**: включение в тренировочную выборку данных, полученных в различных условиях, помогает модели лучше адаптироваться к новым данным.\n",
        "- **Трансферное обучение**: использование предварительно обученных моделей на больших и разнообразных наборах данных может улучшить обобщающую способность модели на новых данных.\n",
        "\n",
        "Этот подход помогает учесть различия в распределениях и сделать модель более универсальной.\n"
      ],
      "metadata": {
        "id": "-Ja2B4j8NYBv"
      }
    }
  ]
}